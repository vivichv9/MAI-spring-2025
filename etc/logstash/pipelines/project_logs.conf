# Логи будут прилетать из beats'ов по порту 5044
input {
    kafka {
      bootstrap_servers => "kafka:29092"
      topics => ["project_logs"]
      consumer_threads => 1
      auto_offset_reset => "earliest"
      retry_backoff_ms => 1000
      metadata_max_age_ms => 30000
    }
}

# filter {
#   # Дропаем лог, если он пришел от неизвестного нам сервиса (по желанию)
#   # Ниже я два раза указал host_metrics_app в списке - это не опечатка. Какого-то лешего в условии, в массиве должно быть минимум 2 элемента.
#   # Так как приложение у нас одно - просто дублируем
#   # Поле service у нас появится благодаря конфигурированию Filebeat
#   if [fields][service] not in ["auth", "money", "orders", "products", "personal_account"] {
#     drop {}
#   }
#   # Оригинальный json-лог, который был сгенерирован вашим приложением, будет лежать по ключу message
#   # (из filebeat'а логи прилетают не в чистом виде)
#   json {
#     source => "message"
#   }
#   # Говорим logstash'у, чтобы в качестве timestamp'а лога он брал именно наш timestamp
#   # (в моем случае поле asctime в теле сообщения в формате "yyyy-MM-dd HH:mm:ss.SSS" и часовом поясе UTC)
#   # и затем подтирал поле asctime.
#   # date {
#   #   match => ["asctime", "yyyy-MM-dd HH:mm:ss.SSS"]
#   #   timezone => "UTC"
#   #   target => "@timestamp"
#   #   remove_field => ["asctime"]
#   # }
# }

output {
    stdout {}
    opensearch {
      hosts => "http://opensearch:9200"
      user => "admin"
      password => "OlfbVWQ_FvzhKRsYsVBW%bL9N_fi%%_B"
      index => "project_logs"
      ssl_certificate_verification => false
    }
}