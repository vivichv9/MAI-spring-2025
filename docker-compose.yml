services:
    postgres:
      build:
        context: .
        dockerfile: Dockerfile-pg
      restart: unless-stopped
      container_name: postgres
      hostname: postgres
      volumes:
        - ./data/pg_data/postgres:/var/lib/postgresql/data
        - ./initdb:/docker-entrypoint-initdb.d
      environment:
        POSTGRES_DB: ${POSTGRES_DB}
        POSTGRES_USER: ${POSTGRES_USER}
        POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      ports:
        - ${POSTGRES_PORT}:5432
      healthcheck:
        test: ["CMD-SHELL", "pg_isready -U superset -d superset"]
        interval: 15s
        timeout: 5s
        retries: 5
      networks:
        - trino-network

    # minio:
    #   image: quay.io/minio/minio
    #   container_name: minio
    #   hostname: minio
    #   env_file:
    #     - .env
    #   ports:
    #     - 9000:9000
    #     - 9001:9001
    #   volumes:
    #     - ./data/minio_data:/minio_data
    #   command: server /minio_data --console-address ":9001"
    #   networks:
    #     - trino-network

    # hive-metastore:
    #   image: starburstdata/hive:3.1.2-e.18
    #   container_name: hive-metastore
    #   hostname: hive-metastore
    #   depends_on:
    #     - postgres
    #   ports:
    #     - "9083:9083"
    #   environment:
    #     HIVE_METASTORE_DRIVER: org.postgresql.Driver 
    #     HIVE_METASTORE_JDBC_URL: jdbc:postgresql://postgres:5432/${HIVE_DATABASE}
    #     HIVE_METASTORE_USER: ${HIVE_USER}
    #     HIVE_METASTORE_PASSWORD: ${HIVE_PASSWORD}
    #     HIVE_METASTORE_WAREHOUSE_DIR: s3://hive/
    #     S3_ENDPOINT: http://minio:9000/
    #     S3_ACCESS_KEY: ${MINIO_ACCESS_KEY}
    #     S3_SECRET_KEY: ${MINIO_SECRET_KEY}
    #     S3_PATH_STYLE_ACCESS: "true"
    #     S3_ENDPOINT_SSL_ENABLED: "false"
    #     HIVE_METASTORE_USERS_IN_ADMIN_ROLE: "admin"
    #     REGION: ""
    #     GOOGLE_CLOUD_KEY_FILE_PATH: ""
    #     AZURE_ADL_CLIENT_ID: ""
    #     AZURE_ADL_CREDENTIAL: ""
    #     AZURE_ADL_REFRESH_URL: ""
    #     AZURE_ABFS_STORAGE_ACCOUNT: ""
    #     AZURE_ABFS_ACCESS_KEY: ""
    #     AZURE_WASB_STORAGE_ACCOUNT: ""
    #     AZURE_ABFS_OAUTH: ""
    #     AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
    #     AZURE_ABFS_OAUTH_CLIENT_ID: ""
    #     AZURE_ABFS_OAUTH_SECRET: ""
    #     AZURE_ABFS_OAUTH_ENDPOINT: ""
    #     AZURE_WASB_ACCESS_KEY: ""
    #   networks:
    #     - trino-network        

    # trino-coordinator:
    #   image: trinodb/trino:latest
    #   container_name: trino
    #   depends_on:
    #     - hive-metastore
    #   ports:
    #     - "18080:8080"
    #   volumes:
    #     - ./etc/trino/catalog:/etc/trino/catalog
    #   networks:
    #     - trino-network

    redis:
      image: redis:latest
      container_name: superset_redis
      hostname: redis
      restart: unless-stopped
      volumes:
        - ./data/redis_data:/data
      networks:
        - trino-network
      ports: 
        - 6380:6379
    superset:
      image: apache/superset:2.1.0  # Фиксируем версию
      container_name: superset_app
      restart: unless-stopped
      ports:
        - "8088:8088"
      environment:
        - SUPERSET_SECRET_KEY=your-secret-key-here  # Замените на реальный ключ
        - SQLALCHEMY_DATABASE_URI=postgresql+psycopg2://superset:superset@postgres:5432/superset    
        - SUPERSET_DATABASE_URI=postgresql+psycopg2://superset:superset@postgres:5432/superset    
        - REDIS_HOST=redis
        - REDIS_PORT=6379
        - CELERY_BROKER_URL=redis://redis:6379/0
        - CELERY_RESULT_BACKEND=redis://redis:6379/0
        - SUPERSET_ENV=prod
        - PYTHONPATH=/app/pythonpath
        - SUPERSET_CONFIG_PATH=/app/pythonpath/superset_config.py
      volumes:
        - ./data/superset_data:/app/superset_home
        - ./etc/superset/superset_config.py:/app/pythonpath/superset_config.py
      depends_on:
        postgres:
          condition: service_healthy
        redis:
          condition: service_started
      networks:
        - trino-network

    superset-worker:
      image: apache/superset:2.1.0
      container_name: superset_worker
      restart: unless-stopped
      environment:
        - SQLALCHEMY_DATABASE_URI=postgresql+psycopg2://superset:superset@postgres:5432/superset
        - SUPERSET_DATABASE_URI=postgresql+psycopg2://superset:superset@postgres:5432/superset
        - SUPERSET_SECRET_KEY=your-secret-key-here
        - CELERY_BROKER_URL=redis://redis:6379/0
        - CELERY_RESULT_BACKEND=redis://redis:6379/0
        - FLASK_ENV=production
        - CELERYD_LOG_LEVEL=INFO
        - C_FORCE_ROOT=true
        - BROKER_CONNECTION_RETRY_ON_STARTUP=true
        - PYTHONPATH=/app/pythonpath
        - SUPERSET_CONFIG_PATH=/app/pythonpath/superset_config.py        
      volumes:
        - ./data/superset_data:/app/superset_home
        - ./etc/superset/superset_config.py:/app/pythonpath/superset_config.py
      depends_on:
        - superset
      networks:
        - trino-network
      command: ["celery", "--app=superset.tasks.celery_app:app", "worker", "--pool=prefork", "-O", "fair", "-c", "4"]

    mongodb:
      image: "mongo:6.0.18"
      ports:
        - "27017:27017"   
      restart: "on-failure"
      networks:
        - trino-network
      volumes:
        - "mongodb_data:/data/db"
        - "mongodb_config:/data/configdb"  

    opensearch:
      image: "opensearchproject/opensearch:2.19.1"
      environment:
        - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g"
        - "bootstrap.memory_lock=true"
        - "discovery.type=single-node"
        - "action.auto_create_index=false"
        - "plugins.security.ssl.http.enabled=false"
        - "plugins.security.disabled=false"
        # Can generate a password for `OPENSEARCH_INITIAL_ADMIN_PASSWORD` using a linux device via:
        # tr -dc A-Z-a-z-0-9_@#%^-_=+ < /dev/urandom | head -c${1:-32}
        - "OPENSEARCH_INITIAL_ADMIN_PASSWORD=OlfbVWQ_FvzhKRsYsVBW%bL9N_fi%%_B"
      ulimits:
        memlock:
          hard: -1
          soft: -1
        nofile:
          soft: 65536
          hard: 65536
      ports:
        - "9203:9200"
        - "9303:9300"    
      restart: "on-failure"
      networks:
        - trino-network
      volumes:
        - "opensearch:/usr/share/opensearch/data"  

    opensearch-dashboard:
      image: opensearchproject/opensearch-dashboards:2.19.1
      restart: always
      environment:
        OPENSEARCH_HOSTS: '["http://opensearch:9200"]' # must be a string with no spaces when specified as an environment variable
        DISABLE_INSTALL_DEMO_CONFIG: "true"
        OPENSEARCH_USERNAME: "admin"
        OPENSEARCH_PASSWORD: "OlfbVWQ_FvzhKRsYsVBW%bL9N_fi%%_B"
      logging:
        driver: "json-file"
        options:
          max-size: "100m"
          max-file: "1"
      volumes:
        - "./etc/opensearch-dashboard/opensearch-dashboards.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml"  
      ports:
        - "5601:5601"
      networks:
        - trino-network
      depends_on:
        - opensearch
   

    zookeeper:
      image: confluentinc/cp-zookeeper:latest
      environment:
        ZOOKEEPER_CLIENT_PORT: 2181
        ZOOKEEPER_TICK_TIME: 2000
      ports:
        - 22181:2181
      networks:
        - trino-network

    kafka:
      image: confluentinc/cp-kafka:latest
      depends_on:
        - zookeeper
      ports:
        - 29092:29092
      hostname: kafka
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_CFG_DEFAULT_REPLICATION_FACTOR: 1
        KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      networks:
        - trino-network
      healthcheck:
        test: ["CMD", "kafka-topics", "--list", "--bootstrap-server", "localhost:29092"]
        interval: 5s
        timeout: 10s
        retries: 10

    kafka-ui:
      image: provectuslabs/kafka-ui
      container_name: kafka-ui
      ports:
        - 8090:8080
      restart: always
      environment:
        - KAFKA_CLUSTERS_0_NAME=local
        - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
        - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
      links:
        - kafka
        - zookeeper
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - trino-network

    logstash:
      image: opensearchproject/logstash-oss-with-opensearch-output-plugin
      container_name: logstash
      hostname: logstash
      restart: always
      environment:
        LS_JAVA_OPTS: "-Xms512m -Xmx512m"
      networks:
        - trino-network
      volumes:
          - ./etc/logstash/config.yml:/usr/share/logstash/config/logstash.yml
          - ./etc/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml
          - ./etc/logstash/pipelines/project_logs.conf:/usr/share/logstash/config/pipelines/project_logs.conf
      depends_on:
        kafka:
          condition: service_healthy

    filebeat:
      build:
        context: .
        dockerfile: Dockerfile-filebeat
      container_name: filebeat
      hostname: filebeat
      restart: always
      volumes:
        - ./logs/project:/var/log/project
      depends_on:
        - kafka
      networks:
        - trino-network

    auth_service:
      build:
        context: ./services/auth
        dockerfile: ./Dockerfile
      container_name: auth_service
      hostname: auth_service
      restart: always
      volumes:
        - ./logs/project/auth:/tmp/logs/
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - trino-network
      ports:
        - 8000:8000
    
    products_service:
      build:
        context: ./services/products
        dockerfile: ./Dockerfile
      container_name: products_service
      hostname: products_service
      restart: always
      volumes:
        - ./logs/project/products:/tmp/logs/
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - trino-network
      ports:
        - 8004:8004

    finance_service:
      build:
        context: ./services/service_finance
        dockerfile: ./Dockerfile
      container_name: finance_service
      hostname: finance_service
      restart: always
      volumes:
        - ./logs/project/finance/logs.txt:/tmp/logs/logs.txt
      ports:
        - 8003:8003
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - trino-network

    orders_service:
      build:
        context: ./services/service_orders
        dockerfile: ./Dockerfile
      container_name: orders_service
      hostname: orders_service
      restart: always
      ports:
        - 8002:8002
      volumes:
        - ./logs/project/orders/logs.txt:/tmp/logs/logs.txt
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - trino-network

    personal_account_service:
      build:
        context: ./services/service_personal_account
        dockerfile: ./Dockerfile
      container_name: personal_account_service
      hostname: personal_account_service
      restart: always
      volumes:
        - ./logs/project/personal_account/logs.txt:/tmp/logs/logs.txt
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - trino-network
      ports:
        - 8001:8001

networks:
  trino-network:
    driver: bridge

volumes:
  mongodb_data:
  mongodb_config:
  opensearch: